{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data evaluation\n",
    "Split allnewMF.csv file into multiple groups by predicate. \n",
    "Sort each group by subject to apply binary search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "NaN = float('nan')\n",
    "regex = re.compile(r\"(^[a-z]{2}/)|(\\(.*\\))|(\\s+)|([_,\\\"])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading generated metafacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../results/wikID/allnewMFgen.csv' #allnewMFrestr\n",
    "\n",
    "allnewMF = pd.read_csv(filename, sep='\\t')\n",
    "allnewMF = allnewMF.replace(np.nan, '-', regex=True)\n",
    "\n",
    "allnewMF = allnewMF.replace(regex, '')\n",
    "allnewMF['oldsubject'] = allnewMF['subject']\n",
    "allnewMF['oldobject'] = allnewMF['object']\n",
    "    \n",
    "allnewMF['subject'] = allnewMF['subject'].str.replace(regex,\"\")\n",
    "allnewMF['object'] = allnewMF['object'].str.replace(regex,\"\")\n",
    "\n",
    "allnewMF['test'] = allnewMF['inDateTime'] + allnewMF['after'] + allnewMF['before']\n",
    "allnewMF = allnewMF[allnewMF['test'] != '---']\n",
    "\n",
    "print(len(allnewMF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix(st):\n",
    "    t = st.find('-')\n",
    "    if t > 0:\n",
    "        rest = st[t:]\n",
    "        y = st[:t]\n",
    "    else:\n",
    "        rest = ''\n",
    "        y = st\n",
    "        \n",
    "    return '%04d%s'%(int(y), rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" string to date \"\"\"\n",
    "def str2date(dt):\n",
    "    #try:\n",
    "    if dt == '-':\n",
    "        return None\n",
    "    m = re.search('(\\d{0,4}\\-\\d{0,2}-\\d{0,2})|(\\d{0,4}\\-\\d{0,2})|((\\d{0,4}))', fix(dt))\n",
    "    if m is None:\n",
    "        #date = \"0\"\n",
    "        print('weird format: ', dt)\n",
    "        return None\n",
    "\n",
    "    if m.group(1) != None:\n",
    "        return datetime.strptime(m.group(1), '%Y-%m-%d')\n",
    "    if m.group(2) != None:\n",
    "        return datetime.strptime(m.group(2), '%Y-%m')\n",
    "    if m.group(3) != None:\n",
    "        return datetime.strptime(m.group(3), '%Y')\n",
    "\n",
    "    \"\"\"except ValueError:\n",
    "        print('here!', dt)\n",
    "        return None\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanceInterval2(validDate, generatedDate, isTimestamp = False):\n",
    "    aux = [str2date(validDate[0]), str2date(validDate[1])]\n",
    "    if aux[1] == None:\n",
    "        A = aux[0]\n",
    "        LA = 0\n",
    "    else:\n",
    "        \"\"\"compute the median of the interval\"\"\"\n",
    "        LA = abs((aux[0] - aux[1]).days)\n",
    "        days = LA / 2\n",
    "        A = aux[0] + timedelta(days=days)\n",
    "    \n",
    "    aux = [str2date(generatedDate[0]), str2date(generatedDate[1])]\n",
    "    if aux[1] == None:\n",
    "        B = aux[0]\n",
    "        LB = 0\n",
    "    elif aux[0] == None:\n",
    "        B = aux[1]\n",
    "        LB = 0\n",
    "    else:\n",
    "        if aux[0] == None:\n",
    "            print(validDate, generatedDate)\n",
    "        LB = abs((aux[0] - aux[1]).days)\n",
    "        days = LB / 2\n",
    "        B = aux[0] + timedelta(days=days)\n",
    "        \n",
    "    dist = abs((A - B).days)/365\n",
    "    #w = 1 / (1 + abs(LA - LB)/365)\n",
    "    \n",
    "    #return w*(1 / (1 + dist))\n",
    "    return dist\n",
    "           \n",
    "\n",
    "def distanceTimestamp2(validDate, generatedDate):\n",
    "    A = str2date(validDate)\n",
    "    B = str2date(generatedDate)\n",
    "    dist = abs((A - B).days)/365\n",
    "    #return 1 / (1 + dist)\n",
    "    return dist\n",
    "    \n",
    "## case 4: ts include in interval\n",
    "def checkContains(validDate, generatedDate):\n",
    "    a = validDate[0] <= generatedDate\n",
    "    b = validDate[1] >= generatedDate\n",
    "    \n",
    "    return a & b\n",
    "\n",
    "def distanceContains2(a, b):\n",
    "    A = [str2date(x) for x in a]\n",
    "    B = str2date(b)\n",
    "    if checkContains(A, B):\n",
    "        LA = abs((A[0] - A[1]).days)\n",
    "        days = LA / 2\n",
    "        M = A[0] + timedelta(days=days)\n",
    "        dist = abs((M - B).days)/365\n",
    "        #return 1 / (1 + dist)\n",
    "        return dist\n",
    "    else:\n",
    "        return .0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutYM(date):\n",
    "    return [x[:7] for x in date]\n",
    "\n",
    "def cutY(date):\n",
    "    return [x[:4] for x in date]\n",
    "\n",
    "def distanceInterval(validDate, generatedDate):\n",
    "    validDate = [fix(x) for x in validDate]\n",
    "    generatedDate = [fix(x) for x in generatedDate]\n",
    "    return [distanceInterval2(validDate, generatedDate),\n",
    "            distanceInterval2(cutYM(validDate), cutYM(generatedDate)),\n",
    "            distanceInterval2(cutY(validDate), cutY(generatedDate))]\n",
    "\n",
    "def distanceTimestamp(validDate, generatedDate):\n",
    "    validDate = fix(validDate)\n",
    "    generatedDate = fix(generatedDate)\n",
    "    return [distanceTimestamp2(validDate, generatedDate),\n",
    "            distanceTimestamp2(validDate[:7], generatedDate[:7]),\n",
    "            distanceTimestamp2(validDate[:4], generatedDate[:4])]\n",
    "\n",
    "def distanceContains(validDate, generatedDate):\n",
    "    validDate = [fix(x) for x in validDate]\n",
    "    generatedDate = fix(generatedDate)\n",
    "    return [distanceContains2(validDate, generatedDate),\n",
    "            distanceContains2(cutYM(validDate), generatedDate[:7]),\n",
    "            distanceContains2(cutY(validDate), generatedDate[:4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addYearsStr(date, years):\n",
    "    date = fix(date)\n",
    "    t = date.find('-')\n",
    "    if t > 0:\n",
    "        rest = date[t:]\n",
    "        y = date[:t]\n",
    "    else:\n",
    "        rest = ''\n",
    "        y = date\n",
    "    y = int(y) + years\n",
    "    \n",
    "    return '%04d%s'%(int(y), rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleStuff(sims, row, rowDF, predicate):\n",
    "    inDateTime = rowDF['inDateTime']\n",
    "    after = rowDF['after']\n",
    "    before = rowDF['before']\n",
    "    \"\"\"if predicate == 'isMarriedTo':\n",
    "        inDateTime = addYearsStr(inDateTime, 18) if inDateTime != '-' else inDateTime\n",
    "        after = addYearsStr(after, 18) if after != '-' else after\"\"\"\n",
    "\n",
    "    if inDateTime != '-':\n",
    "        if row['start'] != '-' and row['end'] != '-':\n",
    "            sim = distanceContains([row['start'], row['end']], inDateTime)\n",
    "        elif row['start'] != '-':\n",
    "            sim = distanceTimestamp(row['start'], inDateTime)\n",
    "        elif row['end'] != '-':\n",
    "            sim = distanceTimestamp(row['end'], inDateTime)\n",
    "    elif after != '-' and before != '-':\n",
    "        if row['start'] != '-' and row['end'] != '-':\n",
    "            sim = distanceInterval([row['start'], row['end']], [after, before])\n",
    "        elif row['start'] != '-':\n",
    "            sim = distanceContains([after, before], row['start'])\n",
    "        elif row['end'] != '-':\n",
    "            sim = distanceContains([after, before], row['end'])\n",
    "    elif after != '-':\n",
    "        if row['start'] != '-' and row['end'] != '-':\n",
    "            sim = distanceContains([row['start'], row['end']], after)\n",
    "        elif row['start'] != '-':\n",
    "            sim = distanceTimestamp(row['start'], after)\n",
    "        elif row['end'] != '-':\n",
    "            sim = distanceTimestamp(row['end'], after)\n",
    "    elif before != '-':\n",
    "        if row['start'] != '-' and row['end'] != '-':\n",
    "            sim = distanceContains([row['start'], row['end']], before)\n",
    "        elif row['start'] != '-':\n",
    "            sim = distanceTimestamp(row['start'], before)\n",
    "        elif row['end'] != '-':\n",
    "            sim = distanceTimestamp(row['end'], before)\n",
    "    #sim = '\\t'.join([str(x) for x in sim])\n",
    "\n",
    "    if inDateTime != '-':\n",
    "        if row['start'] != '-':\n",
    "            #sim += '\\t%f'%(distanceTimestamp2(row['start'], inDateTime))\n",
    "            sim += distanceTimestamp(row['start'], inDateTime)\n",
    "        else:\n",
    "            #sim += '\\t-'\n",
    "            sim.append(NaN)\n",
    "            sim.append(NaN)\n",
    "            sim.append(NaN)\n",
    "        if row['end'] != '-':\n",
    "            #sim += '\\t%f'%(distanceTimestamp2(row['end'], inDateTime))\n",
    "            sim += distanceTimestamp(row['end'], inDateTime)\n",
    "        else:\n",
    "            #sim += '\\t-'\n",
    "            sim.append(NaN)\n",
    "            sim.append(NaN)\n",
    "            sim.append(NaN)\n",
    "    else:\n",
    "        #sim += '\\t-\\t-'\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "    if after != '-' and row['start'] != '-':\n",
    "        #sim += '\\t%f'%(distanceTimestamp2(row['start'], after))\n",
    "        sim += distanceTimestamp(row['start'], after)\n",
    "    else:\n",
    "        #sim += '\\t-'\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "    if before != '-' and row['end'] != '-':\n",
    "        #sim += '\\t%f'%(distanceTimestamp2(row['end'], before))\n",
    "        sim += distanceTimestamp(row['end'], before)\n",
    "    else:\n",
    "        #sim += '\\t-'\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "\n",
    "    sims.append((sim, float(rowDF['Confidence']), float(rowDF['PCA Confidence']), float(rowDF['Head Coverage'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleStuffTS(sims, row, rowDF):\n",
    "    if rowDF['inDateTime'] != '-':\n",
    "        if row['date'] != '-':\n",
    "            sim = distanceTimestamp(row['date'], rowDF['inDateTime'])\n",
    "    elif rowDF['after'] != '-' and rowDF['before'] != '-':\n",
    "        if row['date'] != '-':\n",
    "            sim = distanceContains([rowDF['after'], rowDF['before']], row['date'])\n",
    "    elif rowDF['after'] != '-':\n",
    "        if row['date'] != '-':\n",
    "            sim = distanceTimestamp(row['date'], rowDF['after'])\n",
    "    elif rowDF['before'] != '-':\n",
    "        if  row['date'] != '-':\n",
    "            sim = distanceTimestamp(row['date'], rowDF['before'])\n",
    "    #sim = '\\t'.join([str(x) for x in sim])\n",
    "    \n",
    "    if rowDF['inDateTime'] != '-':\n",
    "        if row['date'] != '-':\n",
    "            #sim += '\\t%f'%(distanceTimestamp2(row['date'], rowDF['inDateTime']))\n",
    "            sim += distanceTimestamp(row['date'], rowDF['inDateTime'])\n",
    "        else:\n",
    "            #sim += '\\t-'\n",
    "            sim.append(NaN)\n",
    "            sim.append(NaN)\n",
    "            sim.append(NaN)\n",
    "    else:\n",
    "        #sim += '\\t-'\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "    if rowDF['after'] != '-':\n",
    "        if row['date'] != '-':\n",
    "            #sim += '\\t%f'%(distanceTimestamp2(row['date'], rowDF['after']))\n",
    "            sim += distanceTimestamp(row['date'], rowDF['after'])\n",
    "        else:\n",
    "            #sim += '\\t-'\n",
    "            sim.append(NaN)\n",
    "            sim.append(NaN)\n",
    "            sim.append(NaN)\n",
    "    else:\n",
    "        #sim += '\\t-'\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "    if rowDF['before'] != '-':\n",
    "        if row['date'] != '-':\n",
    "            #sim += '\\t%f'%(distanceTimestamp2(row['date'], rowDF['before']))\n",
    "            sim += distanceTimestamp(row['date'], rowDF['before'])\n",
    "        else:\n",
    "            #sim += '\\t-'\n",
    "            sim.append(NaN)\n",
    "            sim.append(NaN)\n",
    "            sim.append(NaN)\n",
    "    else:\n",
    "        #sim += '\\t-'\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "        sim.append(NaN)\n",
    "    \n",
    "    sim.append(NaN)\n",
    "    sim.append(NaN)\n",
    "    sim.append(NaN)\n",
    "        \n",
    "    sims.append((sim, float(rowDF['Confidence']), float(rowDF['PCA Confidence']), float(rowDF['Head Coverage'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Log(logfile, rowDF, wikidata, similarity):\n",
    "    logfile.write('%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t %s %s %s %s %s %s\\t%s\\t%s\\t%s\\t%s\\n'%(rowDF['rule'],rowDF['PCA Confidence'],\n",
    "                                                                            rowDF['Head Coverage'],rowDF['Confidence'],\n",
    "                                                                            rowDF['subID'],rowDF['objID'],\n",
    "                                                                            rowDF['subject'], rowDF['predicate'],\n",
    "                                                                            rowDF['object'], rowDF['inDateTime'],\n",
    "                                                                            rowDF['after'], rowDF['before'],\n",
    "                                                                            wikidata,\n",
    "                                                                            '\\t'.join([str(x) for x in similarity[0]]),\n",
    "                                                                            str(similarity[1]), str(similarity[2])))\n",
    "    #logfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "datetype\n",
    "0: timestamp\n",
    "1: time interval\n",
    "\"\"\"\n",
    "def saveNewInputFile(file, rowDF, datetype):\n",
    "    inDateTime = rowDF['inDateTime']\n",
    "    after = rowDF['after']\n",
    "    before = rowDF['before']\n",
    "    if datetype == 0:\n",
    "        dateInfo = 'inDateTime\\t%s'%(inDateTime if inDateTime != '-' else after)\n",
    "    else:\n",
    "        dateInfo = 'after\\t%s\\tbefore\\t%s'%(inDateTime if inDateTime != '-' else after, before)\n",
    "    file.write('-\\t%s\\t%s\\t%s\\t%s\\n'%(rowDF['oldsubject'], rowDF['predicate'], rowDF['oldobject'], dateInfo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS Predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_predicate(predicate, validateFile, subjectLabel, objectLabel):\n",
    "    df = allnewMF[allnewMF['predicate'] == predicate]\n",
    "    print('Records to validate', len(df))\n",
    "    df = df.sort_values('subject')\n",
    "    df['object'].head()    \n",
    "    validDF = pd.read_csv('../../data_tocompare/%s.csv'%(validateFile), sep='\\t')\n",
    "    #validDF = validDF.replace(regex, '')\n",
    "    validDF = validDF.sort_values(subjectLabel)\n",
    "    print('Valid Records', len(validDF))\n",
    "    cs = 0\n",
    "    co = 0\n",
    "    cot = 0\n",
    "    sims = []\n",
    "    sims_tsti = []\n",
    "    sims_tsts = []\n",
    "    file = open('%s.csv'%(predicate), 'w')\n",
    "    logfile = open('%s-log.csv'%(predicate), 'w')\n",
    "    logfile_tsts = open('%s-tsts-log.csv'%(predicate), 'w')\n",
    "    logfile_tsti = open('%s-tsti-log.csv'%(predicate), 'w')\n",
    "    logNoMatch = open('%s-log-nmatch.csv'%(predicate), 'w')\n",
    "    flag = True\n",
    "    objects = {}\n",
    "    #rule = '?f<hasChild>?b?a<isMarriedTo>?f=>?a<hasChild>?b'\n",
    "    for _, row in validDF.iterrows():\n",
    "        if flag:\n",
    "            lastSubject = row[subjectLabel]\n",
    "            flag = False\n",
    "        if lastSubject != row[subjectLabel]:\n",
    "            partialDF = df[df['subID'] == lastSubject]\n",
    "            #partialDF = df[(df['subID'] == lastSubject) & (df['rule'] == rule)]\n",
    "            \n",
    "            cot += len(partialDF)\n",
    "            if len(partialDF) > 0:\n",
    "                # print(lastSubject, objects)\n",
    "                cs += 1\n",
    "                for _, rowDF in partialDF.iterrows():\n",
    "                    mfObj = rowDF['objID']\n",
    "                    # print(\"->\", mfObj)\n",
    "                    if mfObj in objects and not objects[mfObj]['duplicated']:\n",
    "                        # match\n",
    "                        co += 1\n",
    "                        handleStuffTS(sims, objects[mfObj], rowDF)\n",
    "                        if rowDF['after'] != '-' and rowDF['before'] != '-':\n",
    "                            Log(logfile_tsti, rowDF, 'WD: %s'%(objects[mfObj]['date']), sims[-1])\n",
    "                            sims_tsti.append(sims[-1])\n",
    "                        else:\n",
    "                            Log(logfile_tsts, rowDF, 'WD: %s'%(objects[mfObj]['date']), sims[-1])\n",
    "                            sims_tsts.append(sims[-1])\n",
    "                            \n",
    "                        #if sims[-1][0][0] <= 0.1: #meta-facts whose dist are <= 0.1\n",
    "                        if sims[-1][1] >= 0.7: #meta-facts whose conf. are >=0.7\n",
    "                            saveNewInputFile(file, rowDF, 0) # 0: timestamp, 1: time interval\n",
    "                        Log(logfile, rowDF, 'WD: %s'%(objects[mfObj]['date']), sims[-1])\n",
    "                    else:\n",
    "                        # no match\n",
    "                        if mfObj in objects and objects[mfObj]['duplicated']:\n",
    "                            duplicatedInfo = \"%s\\t%s\"%(objects[mfObj]['date'], objects[mfObj]['extras'])\n",
    "                        else:\n",
    "                            duplicatedInfo = \" \\t \"\n",
    "                        logNoMatch.write('%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n'%(rowDF['rule'],rowDF['subject'], \n",
    "                                         rowDF['predicate'],rowDF['object'],\n",
    "                                         rowDF['subID'],rowDF['objID'],\n",
    "                                         rowDF['inDateTime'],rowDF['after'], \n",
    "                                         rowDF['before'], duplicatedInfo))\n",
    "\n",
    "\n",
    "            lastSubject = row[subjectLabel]\n",
    "            objects = {row[objectLabel]: {'date': row['date'], 'duplicated': False }}\n",
    "        else:\n",
    "            if row[objectLabel] in objects:\n",
    "                objects[row[objectLabel]]['duplicated'] = True\n",
    "                if 'extras' in objects[row[objectLabel]]:\n",
    "                    objects[row[objectLabel]]['extras'].append(row['date'])\n",
    "                else:\n",
    "                    objects[row[objectLabel]]['extras'] = [row['date']]\n",
    "            else:\n",
    "                objects[row[objectLabel]] = {'date': row['date'], 'duplicated': False}\n",
    "\n",
    "\n",
    "    file.close()\n",
    "    logfile.close()\n",
    "    logfile_tsts.close()\n",
    "    logfile_tsti.close()\n",
    "    logNoMatch.close()\n",
    "    print(\"Total iqual subject %d\"%cs)\n",
    "    print(\"Total iqual subject-object %d\"%co)\n",
    "    print(\"Total nomatch subject-object %d\"%(cot-co))\n",
    "    return sims, sims_tsts, sims_tsti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TI Predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ti_predicate(predicate, validateFile, subjectLabel, objectLabel):\n",
    "    df = allnewMF[allnewMF['predicate'] == predicate]\n",
    "    print('Records to validate', len(df))\n",
    "    df = df.sort_values('subject')\n",
    "    df['object'].head()\n",
    "    validDF = pd.read_csv('../../data_tocompare/%s.csv'%(validateFile), sep=',')\n",
    "    #validDF = validDF.replace(regex, '')\n",
    "    validDF = validDF.sort_values(subjectLabel)\n",
    "    validDF = validDF.replace(np.nan, '-', regex=True)\n",
    "    print('Valid Records', len(validDF))\n",
    "    cs = 0\n",
    "    co = 0\n",
    "    cot = 0\n",
    "    sims = []\n",
    "    sims_tsts = []\n",
    "    sims_titi = []\n",
    "    sims_tsti = []\n",
    "    file = open('%s.csv'%(predicate), 'w')\n",
    "    logfile = open('%s-log.csv'%(predicate), 'w')\n",
    "    logfile_tsts = open('%s-tsts-log.csv'%(predicate), 'w')\n",
    "    logfile_titi = open('%s-titi-log.csv'%(predicate), 'w')\n",
    "    logfile_tsti = open('%s-tsti-log.csv'%(predicate), 'w')\n",
    "    logNoMatch = open('%s-log-nmatch.csv'%(predicate), 'w')\n",
    "    flag = True\n",
    "    objects = {}\n",
    "    for _, row in validDF.iterrows():\n",
    "        if flag:\n",
    "            lastSubject = row[subjectLabel]\n",
    "            flag = False\n",
    "        if lastSubject != row[subjectLabel]:\n",
    "            partialDF = df[df['subID'] == lastSubject]\n",
    "\n",
    "            cot += len(partialDF)\n",
    "            if len(partialDF) > 0:\n",
    "                # print(lastSubject, objects)\n",
    "                cs += 1\n",
    "                for _, rowDF in partialDF.iterrows():\n",
    "                    mfObj = rowDF['objID']\n",
    "                    # print(\"->\", mfObj)\n",
    "                    if mfObj in objects and not objects[mfObj]['duplicated']:\n",
    "                        # match\n",
    "                        co += 1\n",
    "                        handleStuff(sims, objects[mfObj], rowDF, predicate)\n",
    "                        if rowDF['after'] != '-' and rowDF['before'] != '-' and objects[mfObj]['start'] != '-' and objects[mfObj]['end'] != '-':\n",
    "                            Log(logfile_titi, rowDF, 'WD: %s %s'%(objects[mfObj]['start'], objects[mfObj]['end']), sims[-1])\n",
    "                            sims_titi.append(sims[-1])\n",
    "                        elif (rowDF['after'] != '-' and rowDF['before'] != '-') or (objects[mfObj]['start'] != '-' and objects[mfObj]['end'] != '-'):\n",
    "                            Log(logfile_tsti, rowDF, 'WD: %s %s'%(objects[mfObj]['start'], objects[mfObj]['end']), sims[-1])\n",
    "                            sims_tsti.append(sims[-1])\n",
    "                        else:\n",
    "                            Log(logfile_tsts, rowDF, 'WD: %s %s'%(objects[mfObj]['start'], objects[mfObj]['end']), sims[-1])\n",
    "                            sims_tsts.append(sims[-1])\n",
    "                        \n",
    "                        #if sims[-1][0][0] <= 0.1: #meta-facts whose dist are <= 0.1\n",
    "                        if sims[-1][1] >= 0.7: #meta-facts whose conf. are >=0.7\n",
    "                            saveNewInputFile(file, rowDF, 1) # 0: timestamp, 1: time interval\n",
    "                        Log(logfile, rowDF, 'WD: %s %s'%(objects[mfObj]['start'], objects[mfObj]['end']), sims[-1])\n",
    "                    else:\n",
    "\n",
    "                        if mfObj in objects and objects[mfObj]['duplicated']:\n",
    "                            duplicatedInfo = \"%s %s %s\"%(objects[mfObj]['start'], objects[mfObj]['end'], objects[mfObj]['extras'])\n",
    "                        else:\n",
    "                            duplicatedInfo = \"*\"\n",
    "\n",
    "                        # no match\n",
    "                        logNoMatch.write('%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n'%(rowDF['rule'],rowDF['subject'], \n",
    "                                         rowDF['predicate'],rowDF['object'], \n",
    "                                         rowDF['subID'],rowDF['objID'],\n",
    "                                         rowDF['inDateTime'],rowDF['after'], \n",
    "                                         rowDF['before'], duplicatedInfo))\n",
    "\n",
    "\n",
    "            lastSubject = row[subjectLabel]\n",
    "            objects = {row[objectLabel]: {'start': row['start'], 'end': row['end'], 'duplicated': False }}\n",
    "        else:\n",
    "            if row[objectLabel] in objects:\n",
    "                objects[row[objectLabel]]['duplicated'] = True\n",
    "                if 'extras' in objects[row[objectLabel]]:\n",
    "                    objects[row[objectLabel]]['extras'].append('%s %s'%(row['start'], row['end']))\n",
    "                else:\n",
    "                    objects[row[objectLabel]]['extras'] = ['%s %s'%(row['start'], row['end'])]\n",
    "            else:\n",
    "                objects[row[objectLabel]] = {'start': row['start'], 'end': row['end'], 'duplicated': False}\n",
    "\n",
    "\n",
    "    file.close()\n",
    "    logfile.close()\n",
    "    logfile_tsts.close()\n",
    "    logfile_tsti.close()\n",
    "    logfile_titi.close()\n",
    "    logNoMatch.close()\n",
    "    print(\"Total iqual subject %d\"%cs)\n",
    "    print(\"Total iqual subject-object %d\"%co)\n",
    "    print(\"Total nomatch subject-object %d\"%(cot-co))\n",
    "    \n",
    "    return sims, sims_tsts, sims_tsti, sims_titi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hasChild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simsHasChild, simsHasChild_tsts, simsHasChild_tsti = ts_predicate('hasChild', 'hasChild', 'pId', 'childId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for x in simsHasChild:\n",
    "    c += 1 if 1 >= x[0][0] else 0\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## directed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simsDirected, simsDirected_tsts, simsDirected_tsti = ts_predicate('directed', 'created', 'personId', 'workId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for x in simsDirected:\n",
    "    c += 1 if 0 == x[0][0] else 0\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isMarriedTo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simsIsMarriedTo, simsIsMarriedTo_tsts, simsIsMarriedTo_tsti, simsIsMarriedTo_titi = ti_predicate('isMarriedTo', 'isMarriedTo', 'pId', 'spId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for x in simsIsMarriedTo_tsti:\n",
    "    c += 1 if 0 == x[0][0] else 0\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isAffiliatedTo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simsIsAffiliatedTo, simsIsAffiliatedTo_tsts, simsIsAffiliatedTo_tsti, simsIsAffiliatedTo_titi = ti_predicate('isAffiliatedTo', 'isAffiliatedTo',\n",
    "                                                                                                             'pId', 'affId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for x in simsIsAffiliatedTo:\n",
    "    c += 1 if 0 == x[0][0] else 0\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## playsFor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simsPlaysFor, simsPlaysFor_tsts, simsPlaysFor_tsti, simsPlaysFor_titi = ti_predicate('playsFor', 'isAffiliatedTo',\n",
    "                                                                                     'pId', 'affId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for x in simsPlaysFor:\n",
    "    c += 1 if 0 == x[0][0] else 0\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### worksAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simsWorksAt, simsWorksAt_tsts, simsWorksAt_tsti, simsWorksAt_titi = ti_predicate('worksAt', 'worksAt',\n",
    "                                                                                 'pId', 'compId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for x in simsWorksAt:\n",
    "    c += 1 if 0 == x[0][0] else 0\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create structure to analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'hasChild':       [simsHasChild,simsHasChild_tsts,simsHasChild_tsti],\n",
    "     'directed':       [simsDirected,simsDirected_tsts,simsDirected_tsti],\n",
    "     'isMarriedTo':    [simsIsMarriedTo,simsIsMarriedTo_tsts,simsIsMarriedTo_tsti,simsIsMarriedTo_titi],\n",
    "     'isAffiliatedTo': [simsIsAffiliatedTo,simsIsAffiliatedTo_tsts,simsIsAffiliatedTo_tsti,simsIsAffiliatedTo_titi],\n",
    "     'playsFor':       [simsPlaysFor,simsPlaysFor_tsts,simsPlaysFor_tsti,simsPlaysFor_titi],\n",
    "     'worksAt':        [simsWorksAt,simsWorksAt_tsts,simsWorksAt_tsti,simsWorksAt_titi]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip as gz\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gz.open('similarities_dbp.pkl.gz','wb')\n",
    "pkl.dump(d,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in d:\n",
    "    print(x, len(d[x][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeByColumn(data):\n",
    "    nan = str('NaN')\n",
    "    a, b, c, d = zip(*data)\n",
    "    a = np.array(a, dtype=np.float64)\n",
    "    \n",
    "#     std = np.std(a, axis=0)\n",
    "#     mean = np.mean(a, axis=0)\n",
    "#     lim = mean+2*std\n",
    "    \n",
    "#     for x in a:\n",
    "#         for i in range(len(std)):\n",
    "#             if x[i] > lim[i]:\n",
    "#                 x[i] = nan      \n",
    "    a = a / np.nanmax(a, axis=0)\n",
    "    #print(a)\n",
    "    res = zip(a.tolist(), b, c, d)\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = []\n",
    "similarity_tsts = []\n",
    "similarity_tsti = []\n",
    "similarity_titi = []\n",
    "\n",
    "for key in d:\n",
    "    similarity += normalizeByColumn(d[key][0])\n",
    "    similarity_tsts += normalizeByColumn(d[key][1])\n",
    "    if len(d[key][2]) > 0:\n",
    "        similarity_tsti += normalizeByColumn(d[key][2])\n",
    "    if len(d[key]) > 3 and len(d[key][3]) > 0:\n",
    "        similarity_titi += normalizeByColumn(d[key][3])\n",
    "    \n",
    "print(len(similarity))\n",
    "print(len(similarity_tsts))\n",
    "print(len(similarity_tsti))\n",
    "print(len(similarity_titi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gz.open('totalSimilarities_dbp.pkl.gz','wb')\n",
    "pkl.dump((similarity, similarity_tsts, similarity_tsti, similarity_titi),f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
